{
  "guid": "91B5893E-028B-47BC-9D84-395A60CC1B33",
  "name": "Intel PyTorch GPU Inference Optimization with AMP",
  "categories": ["Toolkit/oneAPI AI And Analytics/Features and Functionality"],
  "description": "This sample illustrates how to use AMP BFLOAT16 in PyTorch on Intel dGPU",
  "builder": ["cli"],
  "languages": [{"python":{}}],
  "os":["linux"],
  "targetDevice": ["GPU"],
  "gpuRequired": ["ats-m","dg2","pvc"],
  "ciTests": {
    "linux": [
    {
        "id": "intel pytorch gpu inference optimization with amp",
        "steps": [
            "pip install uv==0.6.3", 
            "uv sync",
            "uv run jupyter nbconvert --ExecutePreprocessor.enabled=True --to notebook IntelPyTorch_GPU_InferenceOptimization_with_AMP.ipynb"
        ]
    }
    ]
  },
  "expertise": "Code Optimization"
}

