[project]
name = "tensorFlow_fine-tuning_and_inference_for_LLMs_with_bfloat16"
version = "0.1.0"
description = "This sample illustrates how to fine-tune and do inference of a TensorFlow LLM model using Bfloat16."
authors = [
    {name = "Copyright Â© 2023 Intel Corporation"}
]
license = {text = "MIT"}
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "absl-py>=1.4.0",
    "astunparse>=1.6.3",
    "evaluate>=0.4.3",
    "h5py>=3.13.0",
    "huggingface-hub>=0.29.2",
    "intel-extension-for-tensorflow[cpu]>=2.15.0",
    "keras>=2.15.0",
    "keras-preprocessing>=1.1.2",
    "matplotlib>=3.10.1",
    "neural-compressor>=3.3",
    "numpy>=1.26.4",
    "onnxruntime>=1.20.1",
    "pandas>=2.2.3",
    "pillow>=11.1.0",
    "py-cpuinfo>=9.0.0",
    "requests>=2.32.3",
    "tensorboard>=2.15.2",
    "tensorboard-data-server>=0.7.2",
    "tensorboard-plugin-wit>=1.8.1",
    "tf-estimator-nightly>=2.16.0.dev2024012409",
    "tokenizers>=0.21.0",
    "transformers>=4.49.0",
]

[dependency-groups]
dev = [
    "ipykernel>=6.29.5",
    "jupyter>=1.1.1",
]
