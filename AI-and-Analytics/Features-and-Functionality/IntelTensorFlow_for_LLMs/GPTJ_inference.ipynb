{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102d565c-f70d-4e03-8a47-9892f1667032",
   "metadata": {},
   "source": [
    "# Complete your thoughts with GPT-J On Intel Xeon using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970099f-4e62-455c-9ae9-5dfe5ddd495b",
   "metadata": {},
   "source": [
    "This notebook uses HuggingFace's GPT-J model to perform text generation on Intel Xeon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564ed5c-927c-41e2-b4e7-9e06b4b12d7b",
   "metadata": {},
   "source": [
    "## Model :GPT-J (6B)\n",
    " **[GPT-J(6B)] (https://huggingface.co/EleutherAI/gpt-j-6b): released in March 2021.\n",
    "\n",
    "It was the largest open source GPT-3-style language model in the world at the time of release.**\n",
    "\n",
    " **GPT-J is similar to ChatGPT in ability, although it does not function as a chat bot, only as a text predictor.\n",
    "  Developed using Mesh Tranformer & xmap in JAX**\n",
    "\n",
    " *The model consists of :\n",
    ">\n",
    "     - 28 layers\n",
    "     - Model dimension of 4096\n",
    "     - Feedforward dimension of 16384\n",
    "     - 16 heads, each with a dimension of 256.*\n",
    ">\n",
    "\n",
    "The model is trained with a tokenization vocabulary of 50257, using the same set of Byte Pair Encoding(BPEs) as GPT-2/GPT-3.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0d016-88be-4111-92e8-f79d38e89a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForCausalLM\n",
    ")\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d39ff9e-6948-4317-9841-ced595d4e479",
   "metadata": {},
   "source": [
    "### Get Config and Tokenizer for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1e22c-4050-43fd-a477-fb9f6277e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "\n",
    "model_name = \"EleutherAI/gpt-j-6B\"\n",
    "max_output_tokens = 32\n",
    "\n",
    "# Initialize the text tokenizer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1faf746-e288-447f-b7f6-9528145e8663",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e76424-22f8-4386-9899-ac9c292e5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model weights\n",
    "model = TFAutoModelForCausalLM.from_pretrained(model_name, config=config)\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66df92-bb99-4e4c-b210-37001d98f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_kwargs = dict(do_sample=False, num_beams=4, eos_token_id=model.config.eos_token_id)\n",
    "gen = tf.function(lambda x: model.generate(x, max_new_tokens=max_output_tokens, **generate_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861d202-57e3-426b-aeb2-0dd4629e58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_my_thought(x):\n",
    "    tokenized_data = tokenizer([x], return_tensors=\"tf\").input_ids\n",
    "    output = gen(tokenized_data)\n",
    "    decoded = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c85da-51a0-4424-88f3-2a17116a6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_sentence = \"This is a warmup sentence. Warmup helps get the model ready to showcase its capabilities.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edcfa3-a906-4cf6-a5d4-f992b693a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_my_thought(warmup_sentence);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb754511-c933-4117-a4e5-1ae1235c20c7",
   "metadata": {},
   "source": [
    "## Start Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa40c4a-84ca-4991-a5ca-b8a0e4b0f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_sentence1 = \"Ann Arbor is very pleasant in summers. The Huron river is an ideal spot for people to\"\n",
    "input_sentence2 = \"Space is an intersting place. Stephen Hawking hypothesized that there might be multiple universes in which\"\n",
    "input_sentence3 = \"In a shocking finding, scientists discovered a herd of unicorns living in a remote previously unexplored\"\n",
    "input_sentence4 = \"Coffee is one of the most popular drinks in the world. It goes very well with\"\n",
    "input_sentence5 = \"Dogs are often referred to as man's best friend. There are a number of reasons why\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7fcb4-e849-4e0f-98f2-a32703f1139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = complete_my_thought(input_sentence1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7c4fc-0085-4b29-b9a9-a37275242713",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_my_thought(input_sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea86315-107a-44f3-949a-2e972b58976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_my_thought(input_sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d91b8-4290-4ec6-90cc-dce27aa4571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_my_thought(input_sentence4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd82df-a4ba-4723-961a-673f56582926",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_my_thought(input_sentence5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbcb089-09d1-48bd-b384-967a241c1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[CODE_SAMPLE_COMPLETED_SUCCESSFULLY]\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
